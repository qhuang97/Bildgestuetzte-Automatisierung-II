{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b30ffe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5eaf2d",
   "metadata": {},
   "source": [
    "# Creating the Load_Data Function\n",
    "To begin loading the data, let's create a variable that will represent where our dataset is stored. \n",
    "Make sure you put the letter r in front of your path string so that your computer knows that it’s supposed to read the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f26a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\hqpet\\Desktop\\BildAuto_Hausaufgabe\\UE4\\archive\"\n",
    "\n",
    "def load_data(dataset):\n",
    "#The images list will store the image arrays and the class list will store the class number for each image.\n",
    "    images = []\n",
    "    classes = []\n",
    "    \n",
    "    rows = pd.read_csv(dataset)\n",
    "    rows = rows.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    for i, row in rows.iterrows():\n",
    "        img_class = row[\"ClassId\"]\n",
    "        img_path = row[\"Path\"]\n",
    "        image = os.path.join(dataset, img_path)\n",
    "        \n",
    "        image = cv2.imread(image)\n",
    "        image_rs = cv2.resize(image,(img_size,img_size),3)\n",
    "    \n",
    "        R,G,B = cv2.split(image_rs)\n",
    "    \n",
    "        img_r = cv2.equalizeHist(R)\n",
    "        img_g = cv2.equalizeHist(G)\n",
    "        img_b = cv2.equalizeHist(B)\n",
    "    \n",
    "        new_image = cv2.merge((img_r,img_g,img_b))\n",
    "    \n",
    "        if i%500 == 0:\n",
    "            print(f\"loaded:{i}\")\n",
    "        images.append(new_image)\n",
    "        classes.append(img_class)\n",
    "    \n",
    "    X = np.array(images)\n",
    "    y = np.array(classes)\n",
    "    \n",
    "    return (X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d56f67",
   "metadata": {},
   "source": [
    "## Defining Hyperparameters\n",
    "epochs, tells the neural network how many times it should complete a full training process. In this case, the neural network will train itself 20 times (go over all 50,000 images and validate itself with 12,000 test images 20 times)!\n",
    "\n",
    "The learning rate tells us how much the weights will be updated each time. The learning rate is often between 0 and 1.\n",
    "\n",
    "The batch size tells us how much images the neural network will cycle through at once. It would be impossible for the computer to cycle through all 50,000 images at one go, it would crash. That’s why we have the batch size.\n",
    "\n",
    "epochs，告诉神经网络它应该完成多少次完整的训练过程。在这种情况下，神经网络将对自己进行20次训练（对所有50,000张图像进行训练，并用12,000张测试图像对自己进行20次验证）！\n",
    "\n",
    "学习率告诉我们权重每次将被更新多少。学习率通常在0到1之间。\n",
    "\n",
    "批量大小告诉我们，神经网络将一次性循环处理多少图像。计算机不可能一次完成所有50,000张图像的循环，它会崩溃。这就是为什么我们有批量大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e59493d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b4e81",
   "metadata": {},
   "source": [
    "## Loading in the Data\n",
    "First, we’ll define the paths to our test and train datasets, using the same method that we used to define the path to the dataset before\n",
    "\n",
    "Now, we’re going to load both the training and test data in using our load_data function.\n",
    "\n",
    "We’re going to store the images list in the variable trainX, and store the classes list in the trainY variable, and do the same for testX, and testY.\n",
    "\n",
    "Note: This step may take a while, depending on the specs of your computer. Mine took 10–15 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-b528d586a026>\", line 4, in <module>\n",
      "    (trainX, trainY) = load_data(train_data)\n",
      "  File \"<ipython-input-16-459c52e6c0fb>\", line 17, in load_data\n",
      "    image_rs = cv2.resize(image,(img_size,img_size),3)\n",
      "NameError: name 'img_size' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-b528d586a026>\", line 4, in <module>\n",
      "    (trainX, trainY) = load_data(train_data)\n",
      "  File \"<ipython-input-16-459c52e6c0fb>\", line 17, in load_data\n",
      "    image_rs = cv2.resize(image,(img_size,img_size),3)\n",
      "NameError: name 'img_size' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-b528d586a026>\", line 4, in <module>\n",
      "    (trainX, trainY) = load_data(train_data)\n",
      "  File \"<ipython-input-16-459c52e6c0fb>\", line 17, in load_data\n",
      "    image_rs = cv2.resize(image,(img_size,img_size),3)\n",
      "NameError: name 'img_size' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\hqpet\\anaconda3\\envs\\bga2_sose_22_220425\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "train_data = r'C:\\Users\\hqpet\\Desktop\\BildAuto_Hausaufgabe\\UE4\\archive\\Train.csv'\n",
    "test_data = r'C:\\Users\\hqpet\\Desktop\\BildAuto_Hausaufgabe\\UE4\\archive\\Test.csv'\n",
    "\n",
    "(trainX, trainY) = load_data(train_data)\n",
    "(testX, testY) = load_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05e421",
   "metadata": {},
   "source": [
    "## Preparing the Data for Training\n",
    "Now we’re going to normalize the data. This allows us to scale down the values in the data to be between 0 and 1, from before which was between 0 and 255.\n",
    "\n",
    "Next, we’re going to one-hot encode the test and train labels. In essence, one-hot encoding is a way of representing each class with a binary value (1s and 0s) instead of a categorical value (“red” or “blue”). It does this by creating a diagonal matrix where the principal diagonal is ones, and the rest of the values are 0. The matrix has dimensions equal to the number of classes there are (if there are 20 classes, the matrix is a 20X20 matrix). In the matrix, each row represents a different class, so each class has its unique code. If you want to learn more about one-hot encoding, here's a great resource\n",
    "\n",
    "And finally, we’re going to account for inequalities in the classes by assigning a weight to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UPDATE: Normalizing data\")\n",
    "trainX = train_X.astype(\"float32\") / 255.0\n",
    "testX = test_X.astype(\"float32\") / 255.0\n",
    "print(\"UPDATE: One-Hot Encoding data\")\n",
    "num_labels = len(np.unique(train_y))\n",
    "trainY = to_categorical(trainY, num_labels)\n",
    "testY = to_categorical(testY, num_labels)\n",
    "class_totals = trainY.sum(axis=0)\n",
    "class_weight = class_totals.max() / class_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaeb335",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "Before we jump into building the model, I want to point out that there is no “proper” way to build the model. There is no fixed amount of layers, dimensions or types of layers that your CNN has to have. You should play around with it to see which one gives you the best accuracy. I’ll give you the one that gave me the best accuracy.\n",
    "\n",
    "This time, we’re going to create a class, called RoadSignClassifier (any name should do). Within the class, there is one function, createCNN, which takes 4 parameters. We’ll be using the Sequential API, which allows us to create the model layer-by-layer.\n",
    "\n",
    "This is our first convolutional layer. We define the dimension of our output (8 X 8 X 3), and we use the activation function “relu”. We continue with this Conv2D — MaxPooling2D sequence for 2 more times.\n",
    "\n",
    "The same thing as last time, except this time we include batch normalization. It just speeds up training.\n",
    "\n",
    "Now we flatten the output from the final convolutional layer, perform a dropout and enter into our final dense layer. The output in the final dense layer is equal to the number of classes that we have.\n",
    "\n",
    "That’s basically it for building the model. Time to move on ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602ea685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSignClassifier:\n",
    "    def createCNN(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        model.add(Conv2D(8, (5, 5), input_shape=inputShape,      activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation=\"relu\"))\n",
    "        model.add(Dense(classes, activation=\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1babd",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Now its time for the fun part (actually this is the part where we have to wait 30 mins for the model to train lol). Its time to train our model to recognize road signs!\n",
    "\n",
    "Here we’re performing data augmentation. Data augmentation creates modified versions of the images in our dataset. It allows us to add images to our dataset without us having to collect new ones. In Keras, we use the ImageDataGenerator module to perform data augmentation.\n",
    "\n",
    "The first line defines our model. We use the class RoadSignClassifier, and define the width, height, depth and the number of classes.\n",
    "\n",
    "In the second line, we create our optimizer, which in this case is the Adam optimizer. We’ll initialize the learning rate as what we had set it to be previously (0.001), we’ll also set the learning rate to decrease every epoch (that’s the decay parameter, it reduces overfitting).\n",
    "\n",
    "The first line compiles the model. We create the model and define the optimizer, the loss, and the number of epochs.\n",
    "\n",
    "In the second line, we fit out model (this is where the training takes place). Our data_aug.flow method applies the augmentations to our images that we defined before. The number of epochs is set to 20. For the validation data, we use our test data. The verbose is set to 1, which just means that Keras will show the progress of the model being trained as you go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf779f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8e8ca7433bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#数据增强（Data Augmentation）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m data_aug = ImageDataGenerator(rotation_range=10,\n\u001b[0m\u001b[0;32m      3\u001b[0m                               \u001b[0mzoom_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mwidth_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mheight_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "#数据增强（Data Augmentation）\n",
    "data_aug = ImageDataGenerator(rotation_range=10,\n",
    "                              zoom_range=0.15,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.15,\n",
    "                              horizontal_flip=False,\n",
    "                              vertical_flip=False)\n",
    "\n",
    "\n",
    "model = RoadSignClassifier.createCNN(width=32, height=32, depth=3, classes=43)\n",
    "optimizer = Adam(lr=learning_rate, decay=learning_rate / (epochs))\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "fit = model.fit_generator(data_aug.flow(train_X, trainY, batch_size=batch_size), \n",
    "                          epochs=epochs,\n",
    "                          validation_data=(test_X, testY),\n",
    "                          class_weight=class_weight,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b92af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f481cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add48271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a3245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
